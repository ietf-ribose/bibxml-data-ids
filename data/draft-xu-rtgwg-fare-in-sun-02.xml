<reference anchor="I-D.xu-rtgwg-fare-in-sun" target="https://datatracker.ietf.org/doc/html/draft-xu-rtgwg-fare-in-sun-02">
  <front>
    <title>Fully Adaptive Routing Ethernet in Scale-Up Networks</title>
    <author fullname="Xiaohu Xu" initials="X." surname="Xu">
      <organization>China Mobile</organization>
    </author>
    <author fullname="Zongying He" initials="Z." surname="He">
      <organization>Broadcom</organization>
    </author>
    <author fullname="Nan Wang" initials="N." surname="Wang">
      <organization>Hygon</organization>
    </author>
    <author fullname="Hua Wang" initials="H." surname="Wang">
      <organization>Moore Threads</organization>
    </author>
    <author fullname="Jian Guo" initials="J." surname="Guo">
      <organization>Biren Technology</organization>
    </author>
    <author fullname="Xiang Li" initials="X." surname="Li">
      <organization>Enflame Technology</organization>
    </author>
    <author fullname="Tianyou Zhou" initials="T." surname="Zhou">
      <organization>Resnics Technology</organization>
    </author>
    <author fullname="Yongtao Yang" initials="Y." surname="Yang">
      <organization>Centec</organization>
    </author>
    <author fullname="Yinben Xia" initials="Y." surname="Xia">
      <organization>Tencent</organization>
    </author>
    <author fullname="Weifeng Zhang" initials="W." surname="Zhang">
      <organization>Tencent</organization>
    </author>
    <author fullname="Peilong Wang" initials="P." surname="Wang">
      <organization>Baidu</organization>
    </author>
    <author fullname="Yan Zhuang" initials="Y." surname="Zhuang">
      <organization>Huawei Technologies</organization>
    </author>
    <author fullname="Fajie Yang" initials="F." surname="Yang">
      <organization>Cloudnine Information Technologies</organization>
    </author>
    <author fullname="Chao Li" initials="C." surname="Li">
      <organization>Metanet Networking Technology</organization>
    </author>
    <author fullname="Xiaojun Wang" initials="X." surname="Wang">
      <organization>Ruijie Networks</organization>
    </author>
    <date year="2026" month="February" day="26"/>
    <abstract>
      <t>The Mixture of Experts (MoE) has become a dominant paradigm in transformer-based artificial intelligence (AI) large language models (LLMs). It is widely adopted in both distributed training and distributed inference. To enable efficient expert parallelization and even tensor parallelization across dozens or even hundreds of Graphics Processing Units (GPUs) in MoE architectures, an ultra-high- throughput, ultra-low-latency AI scale-up network (SUN) is critical. This document describes how to extend the Weighted Equal-Cost Multi- Path (WECMP) load-balancing mechanism, referred to as Fully Adaptive Routing Ethernet (FARE), which was originally designed for scale-out networks, to scale-up networks.</t>
    </abstract>
  </front>
  <seriesInfo name="Internet-Draft" value="draft-xu-rtgwg-fare-in-sun-02"/>
</reference>