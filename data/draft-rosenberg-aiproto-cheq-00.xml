<reference anchor="I-D.rosenberg-aiproto-cheq" target="https://datatracker.ietf.org/doc/html/draft-rosenberg-aiproto-cheq-00">
  <front>
    <title>CHEQ: A Protocol for Confirmation AI Agent Decisions with Human in the Loop (HITL)</title>
    <author fullname="Jonathan Rosenberg" initials="J." surname="Rosenberg">
      <organization>Five9</organization>
    </author>
    <author fullname="Pat White" initials="P." surname="White">
      <organization>Bitwave</organization>
    </author>
    <author fullname="Cullen Fluffy Jennings" initials="C. F." surname="Jennings">
      <organization>Cisco</organization>
    </author>
    <date year="2025" month="October" day="19"/>
    <abstract>
      <t>This document proposes Confirmation with Human in the Loop (HITL) Exchange of Quotations (CHEQ). CHEQ allows humans to confirm decisions and actions proposed by AI Agents prior to those decisions being acted upon. It also allows humans to provide information required for tool invocation, without disclosing that information to the AI agent, protecting their privacy. CHEQ aims to guarantee that AI Agent hallucinations cannot result in unwanted actions by the human on whose behalf they are made. CHEQ can be integrated into protocols like the Model Context Protocol (MCP), the Agent-to-Agent (A2A) protocol, and the Normalized API for AI Agent Calling Tools (N-ACT) protocol. It makes use of a signed object which can be carried in those protocols.</t>
    </abstract>
  </front>
  <seriesInfo name="Internet-Draft" value="draft-rosenberg-aiproto-cheq-00"/>
</reference>