<reference anchor="I-D.aylward-aiga-1" target="https://datatracker.ietf.org/doc/html/draft-aylward-aiga-1-00">
  <front>
    <title>AI Governance and Accountability Protocol (AIGA)</title>
    <author fullname="Edward Richard Aylward Jr" initials="E. R." surname="Aylward">
      <organization/>
    </author>
    <date year="2025" month="November" day="2"/>
    <abstract>
      <t>This document specifies the AI Governance and Accountability (AIGA) Protocol version 1.0, a practical, economically viable, and technically enforceable framework for governing autonomous AI agents. AIGA 1.0 is designed to address real-world deployment constraints, adversarial agent scenarios, and economic incentive alignment. The protocol is founded on a Tiered Risk-Based Governance model, applying proportional oversight to agents based on their capabilities. All agents are governed by an Immutable Kernel Architecture which provides a non-modifiable Trusted Computing Base (TCB) for enforcing policy. This is combined with Action-Based Authorization, where critical operations require real-time approval. To solve the single-point-of-failure problem, the protocol uses a Federated Authority Network of regional, cross-validating hubs and provides a Network-Level Quarantine Protocol for enforcement. The entire framework is designed around Economic Incentive Alignment, making compliance the most economically rational choice for operators. For high-assurance (T3-T4) scenarios, AIGA 1.0 specifies advanced, redundant mechanisms including Multi-Vendor TEE Attestation (M-TACE), AI "Warden Triumvirate" Triage, Human Review Board (HRB) Multi-Signature, Peer Consensus Failsafe &amp; Identity Rotation, and Double Ratchet Cryptography.</t>
    </abstract>
  </front>
  <seriesInfo name="Internet-Draft" value="draft-aylward-aiga-1-00"/>
</reference>