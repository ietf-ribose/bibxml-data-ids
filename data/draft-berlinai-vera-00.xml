<reference anchor="I-D.berlinai-vera" target="https://datatracker.ietf.org/doc/html/draft-berlinai-vera-00">
  <front>
    <title>VERA: Verifiable Enforcement for Runtime Agents</title>
    <author fullname="Yogami" initials="" surname="Yogami">
      <organization>Berlin AI Labs</organization>
    </author>
    <date year="2026" month="February" day="12"/>
    <abstract>
      <t>AI agents take real actions with real data at machine speed. Compromised AI agents pose significant risks including data exfiltration, unauthorized financial transactions, and cascading failures across downstream systems. This document introduces VERA (Verifiable Enforcement for Runtime Agents), a zero trust reference architecture that provides a structured threat model, five enforcement pillars with typed schemas, four formally stated security properties, and an evidence-based maturity runtime where agents earn autonomy through cryptographic proof rather than calendar time.</t>
    </abstract>
  </front>
  <seriesInfo name="Internet-Draft" value="draft-berlinai-vera-00"/>
</reference>