<reference anchor="I-D.kim-nmrg-rl">
  <front>
    <title>Intelligent Management using Collaborative Reinforcement Multi-agent System</title>
    <author fullname="Min-Suk Kim" initials="M." surname="Kim">
      <organization>Etri</organization>
    </author>
    <author fullname="Yong-Geun Hong" initials="Y." surname="Hong">
      <organization>ETRI</organization>
    </author>
    <author fullname="Youn-Hee Han" initials="Y." surname="Han">
      <organization>KoreaTech</organization>
    </author>
    <date year="2017" month="October" day="30"/>
    <abstract>
      <t>This document describes an intelligent reinforcement learning agent system to autonomously manage agent path-planning over a communication network. The main centralized node called by the global environment should not only manage all agents workflow in a hybrid peer-to-peer networking architecture and, but transfer and share information in distributed nodes. All agents in distributed nodes are able to be provided with a cumulative reward for each action that a given agent takes with respect to an optimized knowledge based on a to-be-learned policy over the learning process. The optimized knowledge would be involved with a large state information by the control action. A reward from the global environment is reflected to the next optimized control action for autonomous path management in distributed networking nodes. The reinforcement learning process (RLP) have developed and expanded to deep reinforcement learning (DRL) with a data-driven approach technique for learning process. The trendy technique has been widely to attempt and apply to networking fields since DRL can be used in practice, since networking areas have the dynamics and heterogeneous environment disturbances, so that in the technique is able to be intelligently learned in the effective strategy.</t>
    </abstract>
  </front>
  <seriesInfo name="Internet-Draft" value="draft-kim-nmrg-rl-01"/>
  <format type="TXT" target="https://www.ietf.org/archive/id/draft-kim-nmrg-rl-01.txt"/>
</reference>