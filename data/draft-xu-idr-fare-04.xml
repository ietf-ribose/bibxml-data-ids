<reference anchor="I-D.xu-idr-fare" target="https://datatracker.ietf.org/doc/html/draft-xu-idr-fare-04">
  <front>
    <title>Fully Adaptive Routing Ethernet using BGP</title>
    <author fullname="Xiaohu Xu" initials="X." surname="Xu">
      <organization>China Mobile</organization>
    </author>
    <author fullname="Shraddha Hegde" initials="S." surname="Hegde">
      <organization>Juniper</organization>
    </author>
    <author fullname="Keyur Patel" initials="K." surname="Patel">
      <organization>Arrcus</organization>
    </author>
    <author fullname="Zongying He" initials="Z." surname="He">
      <organization>Broadcom</organization>
    </author>
    <author fullname="Junjie Wang" initials="J." surname="Wang">
      <organization>Centec</organization>
    </author>
    <author fullname="Hongyi Huang" initials="H." surname="Huang">
      <organization>Huawei</organization>
    </author>
    <author fullname="Qingliang Zhang" initials="Q." surname="Zhang">
      <organization>H3C</organization>
    </author>
    <author fullname="Hang Wu" initials="H." surname="Wu">
      <organization>Ruijie Networks</organization>
    </author>
    <author fullname="Yadong Liu" initials="Y." surname="Liu">
      <organization>Tencent</organization>
    </author>
    <author fullname="Yinben Xia" initials="Y." surname="Xia">
      <organization>Tencent</organization>
    </author>
    <author fullname="Peilong Wang" initials="P." surname="Wang">
      <organization>Baidu</organization>
    </author>
    <author fullname="Tiezheng" initials="" surname="Tiezheng">
      <organization>IEIT SYSTEMS</organization>
    </author>
    <date year="2025" month="December" day="18"/>
    <abstract>
      <t>Large language models (LLMs) like ChatGPT have become increasingly popular in recent years due to their impressive performance in various natural language processing tasks. These models are built by training deep neural networks on massive amounts of text data, as well as visual and video data, and often consist of billions or even trillions of parameters. However, the training process for these models can be extremely resource-intensive, requiring the deployment of thousands or even tens of thousands of GPUs in a single AI training cluster. Therefore, three-stage or even five-stage CLOS networks are commonly adopted for AI networks. The non-blocking nature of the network becomes increasingly critical for large-scale AI model training. Therefore, adaptive routing is necessary to dynamically distribute traffic to the same destination across multiple equal-cost paths, based on network capacity and even congestion information along those paths.</t>
    </abstract>
  </front>
  <seriesInfo name="Internet-Draft" value="draft-xu-idr-fare-04"/>
</reference>